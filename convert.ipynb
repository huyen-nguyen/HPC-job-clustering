{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "with open(\"SelectedJobData_0801-1001.pkl\", \"rb\") as f:\n",
    "    object = pkl.load(f)\n",
    "    \n",
    "df = pd.DataFrame(object)\n",
    "df.to_csv(r'SelectedJobData_0801-1001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# extract fields\n",
    "fields = ['_id', 'group', 'owner', 'job_name', 'job_number', 'slots', 'mem', 'submission_time', 'start_time', 'end_time']\n",
    "df = pd.read_csv('data/0_raw_data.csv', skipinitialspace=True, usecols=fields)\n",
    "\n",
    "# save to\n",
    "df.to_csv(r'data/1_selection_data.csv', index = False)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show difference in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id', 'group', 'owner', 'job_name', 'job_number', 'submission_time', 'start_time', 'end_time', 'mem', 'slots', 'queuetime', 'runtime']\n"
     ]
    }
   ],
   "source": [
    "# remove the incorrect records ------------------\n",
    "\n",
    "df = pd.read_csv(\"data/1_selection_data.csv\", parse_dates=True)\n",
    "\n",
    "# Tq = log( start_time - submit_time )\n",
    "df[\"queuetime\"] = (pd.to_datetime(df[\"start_time\"], format='%Y-%m-%d %H:%M:%S') - pd.to_datetime(df[\"submission_time\"], format='%Y-%m-%d %H:%M:%S')).dt.total_seconds()\n",
    "\n",
    "# Tr = log( end_time - start_time )\n",
    "df[\"runtime\"] = (pd.to_datetime(df[\"end_time\"], format='%Y-%m-%d %H:%M:%S') - pd.to_datetime(df[\"start_time\"], format='%Y-%m-%d %H:%M:%S')).dt.total_seconds()\n",
    "\n",
    "# Remove negative records and convert 0 -> 0.[0]1 ------------------\n",
    "\n",
    "df = df[(df.mem >= 0.0) & (df.slots >= 0.0) & (df.queuetime >= 0.0) & (df.runtime >= 0.0)]\n",
    "\n",
    "df.to_csv(r'data/2_non_neg.csv', index = False)\n",
    "\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of scaling\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "attr = ['mem', 'slots', 'queuetime', 'runtime']\n",
    "\n",
    "df[\"slots\"] = df[\"slots\"] / 36\n",
    "\n",
    "# retrieve just the numeric input values\n",
    "data = df[attr].to_numpy()\n",
    "\n",
    "# perform a robust scaler transform of the dataset\n",
    "trans = StandardScaler()\n",
    "data = trans.fit_transform(data)\n",
    "\n",
    "# convert the array back to a dataframe\n",
    "dataset = DataFrame(data)\n",
    "\n",
    "features = ['N_n', 'M_u', 'T_q', 'T_r']\n",
    "\n",
    "dataset.columns = features\n",
    "\n",
    "dataset.to_csv(r'data/scaled.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"data/2_non_neg.csv\", parse_dates=True)\n",
    "\n",
    "attr = ['mem', 'slots', 'queuetime', 'runtime']\n",
    "\n",
    "df[\"slots\"] = df[\"slots\"] / 36\n",
    "\n",
    "# retrieve just the numeric input values\n",
    "data = df[attr].to_numpy()\n",
    "\n",
    "# convert the array back to a dataframe\n",
    "dataset = DataFrame(data)\n",
    "\n",
    "features = ['N_n', 'M_u', 'T_q', 'T_r']\n",
    "\n",
    "dataset.columns = features\n",
    "\n",
    "dataset.to_csv(r'data/data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id', 'group', 'owner', 'job_name', 'job_number', 'N_n', 'M_u', 'T_q', 'T_r']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# read data\n",
    "df = pd.read_csv(\"data/2_non_neg.csv\", parse_dates=True)\n",
    "\n",
    "df = df.replace([0],0.0000000001)\n",
    "\n",
    "# Nn = log( nproc/Cn )\n",
    "df[\"N_n\"] = np.log(df[\"slots\"]/36)\n",
    "\n",
    "# Mu = log( mem_used )\n",
    "df[\"M_u\"] = np.log(df[\"mem\"])\n",
    "\n",
    "# Tq = log( start_time - submit_time )\n",
    "df[\"T_q\"] = np.log(df[\"queuetime\"])\n",
    "\n",
    "# Tr = log( end_time - start_time )\n",
    "df[\"T_r\"] = np.log(df[\"runtime\"])\n",
    "\n",
    "df.drop(['submission_time', 'start_time', 'end_time', 'mem', 'slots', 'queuetime', 'runtime'], inplace=True, axis=1)\n",
    "\n",
    "df.to_csv(r'data/log_data.csv', index = False)\n",
    "\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the lowest non-zero\n",
    "df[df['mem'].gt(0)].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract date time\n",
    "import datetime as dt\n",
    "\n",
    "start = job_accounting[\"start_time\"][0]\n",
    "submit = job_accounting[\"submission_time\"][0]\n",
    "print(start, submit)\n",
    "\n",
    "a = dt.datetime.strptime(start, '%Y-%m-%d %H:%M:%S')\n",
    "b = dt.datetime.strptime(submit, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Smaller data\n",
    "\n",
    "rows = 5000\n",
    "\n",
    "df1 = pd.read_csv(\"data/2_non_neg.csv\", skipinitialspace=True)\n",
    "df1['id'] = df1['group'] + \"_\" + df1['_id'].str.slice(-5,-1)  \n",
    "df1a = df1['id'].head(rows)\n",
    "\n",
    "df2 = pd.read_csv(\"data/data_all.csv\", skipinitialspace=True)\n",
    "df2 = df2.head(rows)\n",
    "\n",
    "df3 = pd.concat([df1a, df2], axis=1, ignore_index=True)\n",
    "df3.columns = ['name', 'N_n', 'M_u', 'T_q', 'T_r']\n",
    "\n",
    "df3.to_csv(r'data/data.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/1_selection_data.csv', skipinitialspace=True)\n",
    "\n",
    "df['_id'][1][-5:-1]\n",
    "# pd.unique(df['owner']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv', skipinitialspace=True)\n",
    "\n",
    "df[~df.name.str.contains('\\w')].name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
